{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rj_bx2SFHB09",
    "outputId": "9219a1eb-c2f1-41e4-e203-a9c0bf89688e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/codespace/.python/current/lib/python3.12/site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/codespace/.python/current/lib/python3.12/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: spark-nlp in /home/codespace/.python/current/lib/python3.12/site-packages (5.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzbYPcMUHCGY",
    "outputId": "b0acf7a8-8f35-4fa1-a01c-d6d4b1c176d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 08:00:00 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 08:00:04 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/11/23 08:00:05 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/11/23 08:00:06 WARN DAGScheduler: Broadcasting large task binary with size 8.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test set accuracy: 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 08:00:15 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "[Stage 23:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment summary for AAPL: {'Positive - News is likely viewed favorably.': '3 articles, likely viewed as News is likely viewed favorably.', 'Negative - News is likely viewed unfavorably.': '6 articles, likely viewed as News is likely viewed unfavorably.', 'Neutral - News is seen as neither clearly good nor bad.': '1 articles, likely viewed as News is seen as neither clearly good nor bad.'}\n",
      "Opinion Score: 0.30 (Positive Articles: 3, Total Articles: 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/23 08:00:17 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sparknlp\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, Normalizer, LemmatizerModel, StopWordsCleaner\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Start Spark session with Spark NLP\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# Function to fetch news data from TickerTick API\n",
    "def fetch_news_from_ticker_tick(tickers, n=10):\n",
    "    api_url = \"https://api.tickertick.com/feed\"\n",
    "    news_data = []\n",
    "    for ticker in tickers:\n",
    "        params = {\n",
    "            'q': f\"tt:{ticker}\",\n",
    "            'n': n\n",
    "        }\n",
    "        response = requests.get(api_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            for story in data['stories']:\n",
    "                news_data.append((ticker, story['title']))\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {ticker}, Status: {response.status_code}\")\n",
    "        time.sleep(1)  # Sleep to avoid hitting rate limits\n",
    "    return news_data\n",
    "\n",
    "# Tickers to use now\n",
    "ticker_list = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"TSLA\"]\n",
    "\n",
    "# Fetch news data\n",
    "news_data = fetch_news_from_ticker_tick(ticker_list)\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(news_data, schema=[\"ticker\", \"text\"])\n",
    "\n",
    "# Set up the NLP pipeline\n",
    "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
    "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
    "normalizer = Normalizer().setInputCols([\"token\"]).setOutputCol(\"normalized\")\n",
    "stop_words_cleaner = StopWordsCleaner().setInputCols([\"normalized\"]).setOutputCol(\"cleanTokens\")\n",
    "lemmatizer = LemmatizerModel.pretrained(\"lemma_antbnc\", lang=\"en\").setInputCols([\"cleanTokens\"]).setOutputCol(\"lemmas\")\n",
    "\n",
    "pipeline = Pipeline(stages=[document_assembler, tokenizer, normalizer, stop_words_cleaner, lemmatizer])\n",
    "model = pipeline.fit(df)\n",
    "result = model.transform(df)\n",
    "\n",
    "# Convert column to string array type\n",
    "convert_to_string_array = udf(lambda x: x, ArrayType(StringType()))\n",
    "result = result.withColumn(\"tokens\", convert_to_string_array(col(\"lemmas.result\")))\n",
    "\n",
    "# Feature transformation\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(result)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "# Prepare data for modeling\n",
    "random_label_udf = udf(lambda: random.randint(0, 1), IntegerType())\n",
    "rescaledData = rescaledData.withColumn(\"label\", random_label_udf())\n",
    "\n",
    "# Split data and train the model\n",
    "train, test = rescaledData.randomSplit([0.8, 0.2], seed=12345)\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"label\")\n",
    "nbModel = nb.fit(train)\n",
    "predictions = nbModel.transform(test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nbAccuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Naive Bayes Test set accuracy: {nbAccuracy:.2f}\")\n",
    "\n",
    "# Define a UDF to classify sentiment based on probabilities\n",
    "def classify_sentiment(probabilities):\n",
    "    positive_prob = probabilities[1]\n",
    "    if positive_prob > 0.6:\n",
    "        return 'Positive - News is likely viewed favorably.'\n",
    "    elif positive_prob < 0.4:\n",
    "        return 'Negative - News is likely viewed unfavorably.'\n",
    "    else:\n",
    "        return 'Neutral - News is seen as neither clearly good nor bad.'\n",
    "\n",
    "classify_sentiment_udf = udf(classify_sentiment, StringType())\n",
    "\n",
    "# Function to fetch sentiment for a given ticker\n",
    "def get_sentiment_for_ticker(ticker):\n",
    "    ticker_df = df.filter(df.ticker == ticker)\n",
    "    if ticker_df.count() == 0:\n",
    "        return \"No data available for ticker: \" + ticker\n",
    "    processed_df = model.transform(ticker_df)\n",
    "    processed_df = processed_df.withColumn(\"tokens\", convert_to_string_array(col(\"lemmas.result\")))\n",
    "    featurizedData = hashingTF.transform(processed_df)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    predictions = nbModel.transform(rescaledData)\n",
    "    predictions = predictions.withColumn(\"sentiment\", classify_sentiment_udf(predictions.probability))\n",
    "\n",
    "    sentiment_counts = predictions.groupBy(\"sentiment\").count().collect()\n",
    "    sentiment_summary = {row['sentiment']: f\"{row['count']} articles, likely viewed as {row['sentiment'].split(' - ')[1]}\" for row in sentiment_counts}\n",
    "\n",
    "    # Calculate the opinion score\n",
    "    total_articles = sum(count['count'] for count in sentiment_counts)\n",
    "    positive_articles = next((count['count'] for count in sentiment_counts if 'Positive' in count['sentiment']), 0)\n",
    "    if total_articles > 0:\n",
    "        opinion_score = positive_articles / total_articles\n",
    "    else:\n",
    "        opinion_score = 0\n",
    "\n",
    "    return {\n",
    "        'sentiment_summary': sentiment_summary,\n",
    "        'opinion_score': f\"{opinion_score:.2f} (Positive Articles: {positive_articles}, Total Articles: {total_articles})\"\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "ticker_input = input(\"Enter a stock ticker: \").upper()\n",
    "sentiment_results = get_sentiment_for_ticker(ticker_input)\n",
    "print(f\"Sentiment summary for {ticker_input}: {sentiment_results['sentiment_summary']}\")\n",
    "print(f\"Opinion Score: {sentiment_results['opinion_score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
